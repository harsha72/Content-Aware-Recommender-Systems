{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gd_s728FcVH",
        "outputId": "b025ee31-503f-4e2d-c066-ea14775a9cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import datetime\n",
        "import time\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pickle\n",
        "from numpy.linalg import cholesky\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm.notebook\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDGcp8O1qJdn",
        "outputId": "2252e445-69d1-4907-857b-aa28297d164a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 28 00:47:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "GPU available: True\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "else:\n",
        "    print(gpu_info)\n",
        "\n",
        "print(f'GPU available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmFAw4uiDsyi",
        "outputId": "576f52c3-e68a-46ef-f852-5d7b2ed7e7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3hbAOZx6rFoC"
      },
      "outputs": [],
      "source": [
        "behaviour_train_file = '/content/drive/My Drive/code/MINDsmall_train/behaviors.tsv'\n",
        "news_train_file = '/content/drive/My Drive/code/MINDsmall_train/news.tsv'\n",
        "\n",
        "behaviour_dev_file = '/content/drive/My Drive/code/MINDsmall_dev/behaviors.tsv'\n",
        "news_dev_file = '/content/drive/My Drive/code/MINDsmall_dev/news.tsv'\n",
        "\n",
        "# behaviour_train_file = 'MINDsmall_train/behaviors.tsv'\n",
        "# news_train_file = 'MINDsmall_train/news.tsv'\n",
        "\n",
        "# behaviour_dev_file = 'MINDsmall_dev/behaviors.tsv'\n",
        "# news_dev_file = 'MINDsmall_dev/news.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JYjzMlDvFa3g"
      },
      "outputs": [],
      "source": [
        "def newsample(nnn,ratio):\n",
        "    if ratio >len(nnn):\n",
        "        return random.sample(nnn*(ratio//len(nnn)+1),ratio)\n",
        "    else:\n",
        "        return random.sample(nnn,ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgWlqyXjaABh",
        "outputId": "20ed7fed-c25f-4e01-bf2c-bf38d3912589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41690 70973\n"
          ]
        }
      ],
      "source": [
        "################# Reading news data \n",
        "# max_sentence_len = 0\n",
        "sent_len_for_model = 30\n",
        "with open(news_train_file) as news_f:\n",
        "  news_k = news_f.readlines()\n",
        "\n",
        "news_dict = {}\n",
        "content ={}\n",
        "word_dict_raw={'PADDING':[0,999999]}\n",
        "\n",
        "i=0\n",
        "for doc in news_k:\n",
        "  d = doc.strip().split('\\t')\n",
        "  newsid = d[0]\n",
        "  ## Format is id,category,sub-category,Title,Abstract,link,Wikidata/metadata\n",
        "  if newsid not in news_dict:\n",
        "    news_dict[newsid] = len(news_dict)\n",
        "    tokenized_news = word_tokenize(d[3].lower())\n",
        "    tokenized_body = word_tokenize(d[4].lower())\n",
        "    # max_sentence_len = max(max_sentence_len,len(tokenized_news))\n",
        "    content[news_dict[newsid]] = [d[1].lower(),d[2].lower(),tokenized_news,tokenized_body]\n",
        "    for word in tokenized_news:\n",
        "        if word in word_dict_raw:\n",
        "            word_dict_raw[word][1]+=1\n",
        "        else:\n",
        "            word_dict_raw[word]=[len(word_dict_raw),1]\n",
        "    for word in tokenized_body:\n",
        "        if word in word_dict_raw:\n",
        "            word_dict_raw[word][1]+=1\n",
        "        else:\n",
        "            word_dict_raw[word]=[len(word_dict_raw),1]\n",
        "\n",
        "word_dict={}\n",
        "for i in word_dict_raw:\n",
        "    if word_dict_raw[i][1]>=2:\n",
        "        word_dict[i]=[len(word_dict),word_dict_raw[i][1]]\n",
        "print(len(word_dict),len(word_dict_raw))\n",
        "\n",
        "\n",
        "##### words for each news\n",
        "news_words=[]\n",
        "news_index={}\n",
        "news_body_words=[]\n",
        "for newsid in content:\n",
        "    word_id=[]\n",
        "    news_dict[newsid]=len(news_index)\n",
        "    for word in content[newsid][2]:\n",
        "        if word in word_dict:\n",
        "            word_id.append(word_dict[word][0])\n",
        "    word_id=word_id[:30]\n",
        "    news_words.append(word_id+[0]*(30-len(word_id)))\n",
        "\n",
        "    word_id=[]\n",
        "    for word in content[newsid][3]:\n",
        "        if word in word_dict:\n",
        "            word_id.append(word_dict[word][0])\n",
        "    word_id=word_id[:30]\n",
        "    news_body_words.append(word_id+[0]*(30-len(word_id)))\n",
        "\n",
        "news_words=np.array(news_words,dtype='int32')\n",
        "news_body_words=np.array(news_body_words,dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sQHJw1HOVdpV"
      },
      "outputs": [],
      "source": [
        "cat_to_id = {}\n",
        "cat_news_to_id = []\n",
        "subcat_to_id = {}\n",
        "subcat_news_to_id = []\n",
        "\n",
        "for newsid in content: \n",
        "    cat = content[newsid][0]\n",
        "    if cat not in cat_to_id:\n",
        "        cat_to_id[cat] = len(cat_to_id)\n",
        "    \n",
        "    subcat = content[newsid][1]\n",
        "    if subcat not in subcat_to_id:\n",
        "        subcat_to_id[subcat] = len(subcat_to_id)\n",
        "\n",
        "for newsid in content: \n",
        "    cat_news_to_id.append([cat_to_id[content[newsid][0]]])\n",
        "    subcat_news_to_id.append([subcat_to_id[content[newsid][1]]])\n",
        "\n",
        "cat_news_to_id=np.array(cat_news_to_id ,dtype='int32')\n",
        "subcat_news_to_id=np.array(subcat_news_to_id ,dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YgvY5XQTDiPE"
      },
      "outputs": [],
      "source": [
        "def get_embedding(word_dict):\n",
        "    embedding_dict={}\n",
        "    cnt=0\n",
        "    # with open('/data/wuch/glove.840B.300d.txt','rb')as f:\n",
        "    with open('/content/drive/My Drive/code/glove.840B.300d.txt','rb') as f:\n",
        "    # with open('glove.840B.300d.txt','rb') as f:\n",
        "        linenb=0\n",
        "        while True:\n",
        "            line=f.readline()\n",
        "            if len(line)==0:\n",
        "                break\n",
        "            line = line.split()\n",
        "            word=line[0].decode()\n",
        "            linenb+=1\n",
        "            if len(word) != 0:\n",
        "                vec=[float(x) for x in line[1:]]\n",
        "                if word in word_dict:\n",
        "                    embedding_dict[word]=vec\n",
        "                    if cnt%1000==0:\n",
        "                        print(cnt,linenb,word)\n",
        "                    cnt+=1\n",
        "\n",
        "    embedding_matrix=[0]*len(word_dict)\n",
        "    cand=[]\n",
        "    for i in embedding_dict:\n",
        "        embedding_matrix[word_dict[i][0]]=np.array(embedding_dict[i],dtype='float32')\n",
        "        cand.append(embedding_matrix[word_dict[i][0]])\n",
        "    cand=np.array(cand,dtype='float32')\n",
        "    mu=np.mean(cand, axis=0)\n",
        "    Sigma=np.cov(cand.T)\n",
        "    norm=np.random.multivariate_normal(mu, Sigma, 1)\n",
        "    for i in range(len(embedding_matrix)):\n",
        "        if type(embedding_matrix[i])==int:\n",
        "            embedding_matrix[i]=np.reshape(norm, 300)\n",
        "    embedding_matrix[0]=np.zeros(300,dtype='float32')\n",
        "    embedding_matrix=np.array(embedding_matrix,dtype='float32')\n",
        "    # print(embedding_matrix.shape)\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUQT_mz0qX4T",
        "outputId": "487f847b-ec90-441d-8ae2-c0b8db91e37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1 ,\n",
            "1000 1307 round\n",
            "2000 2825 worst\n",
            "3000 4403 harder\n",
            "4000 6093 galleries\n",
            "5000 7790 jumped\n",
            "6000 9578 tray\n",
            "7000 11499 mat\n",
            "8000 13516 adjusting\n",
            "9000 15701 melting\n",
            "10000 17974 dudes\n",
            "11000 20343 11:20\n",
            "12000 22995 3:15\n",
            "13000 25808 william\n",
            "14000 28842 coined\n",
            "15000 32181 vandalism\n",
            "16000 35968 sheen\n",
            "17000 40065 gymnasium\n",
            "18000 44692 poisons\n",
            "19000 50027 offbeat\n",
            "20000 55862 notifies\n",
            "21000 62407 qb\n",
            "22000 70436 chimps\n",
            "23000 80418 twain\n",
            "24000 92330 cost-saving\n",
            "25000 106593 herman\n",
            "26000 124525 turnarounds\n",
            "27000 146919 cosmonaut\n",
            "28000 174454 strong-arm\n",
            "29000 210671 rochelle\n",
            "30000 261472 19-point\n",
            "31000 322856 meier\n",
            "32000 413098 28-19\n",
            "33000 541277 galatasaray\n",
            "34000 749826 boothbay\n",
            "35000 1083521 emmerich\n",
            "36000 1746187 un-christian\n"
          ]
        }
      ],
      "source": [
        "embedding_mat=get_embedding(word_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzF63Xn7Xh-S"
      },
      "source": [
        "Sampling the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K5zc-PfNYCHf"
      },
      "outputs": [],
      "source": [
        "################# Reading click behavior data \n",
        "min_neg_samples_required = 10\n",
        "npratio = 4\n",
        "#########################\n",
        "with open(behaviour_train_file) as f2:\n",
        "  userdata_new = f2.readlines()\n",
        "\n",
        "userid_dict_total = {}\n",
        "cnt_gr = 0\n",
        "cnt = 0 \n",
        "############################################\n",
        "all_train_id=[]\n",
        "all_train_pn=[]    \n",
        "all_label=[]\n",
        "all_user_pos=[]\n",
        "\n",
        "############################################\n",
        "\n",
        "for user in userdata_new:\n",
        "  cnt +=1\n",
        "  line = user.strip().split('\\t')\n",
        "  userid = line[1]\n",
        "  impre_id = line[0]\n",
        "  if userid not in userid_dict_total:\n",
        "    userid_dict_total[userid] = len(userid_dict_total)\n",
        "  click_history = line[3].strip().split()\n",
        "  new_line = line[4].strip().split()\n",
        "  trainpos=[x.split('-')[0]  for x in new_line if x[-1]=='1']\n",
        "  trainneg=[x.split('-')[0] for x in new_line if x[-1]=='0']\n",
        "  \n",
        "  if len(trainneg) > 0:\n",
        "      for pos_sample in trainpos:\n",
        "          pos_neg_sample = newsample(trainneg,npratio)\n",
        "          pos_neg_sample.append(pos_sample)\n",
        "          temp_label=[0 for i in range(npratio)]+[1]\n",
        "          temp_id=list(range(npratio+1))\n",
        "          random.shuffle(temp_id)\n",
        "\n",
        "          shuffle_sample=[]\n",
        "          shuffle_label=[]\n",
        "          for id in temp_id:\n",
        "              shuffle_sample.append(news_dict[pos_neg_sample[id]])\n",
        "              shuffle_label.append(temp_label[id])\n",
        "          posset=list(set(click_history)-set([pos_sample]))\n",
        "          allpos=[news_dict[p] for p in random.sample(posset,min(50,len(posset)))[:50]]\n",
        "          allpos+=[0]*(50-len(allpos))\n",
        "          all_train_pn.append(shuffle_sample)\n",
        "          all_label.append(shuffle_label)\n",
        "          all_train_id.append(userid_dict_total[userid])\n",
        "          all_user_pos.append(allpos)\n",
        "############################################\n",
        "all_train_pn_total=np.array(all_train_pn,dtype='int32')\n",
        "all_label_total=np.array(all_label,dtype='int32')\n",
        "all_train_id_total=np.array(all_train_id,dtype='int32')\n",
        "all_user_pos_total=np.array(all_user_pos,dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N9vqWWHwqX6g"
      },
      "outputs": [],
      "source": [
        "def dcg_score(y_true, y_score, k=10):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    gains = 2 ** y_true - 1\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gains / discounts)\n",
        "\n",
        "\n",
        "def ndcg_score(y_true, y_score, k=10):\n",
        "    best = dcg_score(y_true, y_true, k)\n",
        "    actual = dcg_score(y_true, y_score, k)\n",
        "    return actual / best\n",
        "\n",
        "\n",
        "def mrr_score(y_true, y_score):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order)\n",
        "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
        "    return np.sum(rr_score) / np.sum(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHZtMR6cbCYa",
        "outputId": "cc4002f3-e9d5-4ee7-9827-a50b52bd8f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(236344, 5)\n",
            "(236344, 5)\n",
            "(236344,)\n",
            "(236344, 50)\n"
          ]
        }
      ],
      "source": [
        "print(all_train_pn_total.shape)\n",
        "print(all_label_total.shape)\n",
        "print(all_train_id_total.shape)\n",
        "print(all_user_pos_total.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yGMZyJkyJfKI"
      },
      "outputs": [],
      "source": [
        "unique_users,user_counts = np.unique(all_train_id_total,return_counts=True)\n",
        "selected_user_ids = unique_users[user_counts>15]\n",
        "########################\n",
        "final_id_mask = np.isin(all_train_id_total,selected_user_ids)\n",
        "\n",
        "final_pn_total= all_train_pn_total[final_id_mask,]\n",
        "final_label_total = all_label_total[final_id_mask,]\n",
        "final_id_total = all_train_id_total[final_id_mask]\n",
        "final_user_pos_total = all_user_pos_total[final_id_mask,]\n",
        "###################\n",
        "unique_id,first_occurance = np.unique(np.flip(final_id_total),return_index=True)\n",
        "final_index = len(final_id_total)-1-first_occurance\n",
        "######################\n",
        "all_index = np.array(range(0,len(final_id_total)))\n",
        "\n",
        "test_index = np.isin(all_index,final_index)\n",
        "\n",
        "train_index = ~test_index\n",
        "##########################\n",
        "all_test_cand_news = final_pn_total[test_index,]\n",
        "all_test_cand_label = final_label_total[test_index,]\n",
        "all_test_usr_ids = final_id_total[test_index]\n",
        "all_test_browsed_news = final_user_pos_total[test_index,]\n",
        "# all_test_index = np.array(range(0,len(all_test_usr_ids)))\n",
        "\n",
        "all_train_cand_news = final_pn_total[train_index,]\n",
        "all_train_cand_label = final_label_total[train_index,]\n",
        "all_train_usr_ids = final_id_total[train_index]\n",
        "all_train_browsed_news = final_user_pos_total[train_index,]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivVwZ2NMY5qm",
        "outputId": "265fe02d-7241-428b-8dc9-0c08c0fdde62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54335, 5)\n",
            "(54335, 5)\n",
            "(54335,)\n",
            "(54335, 50)\n"
          ]
        }
      ],
      "source": [
        "print(all_train_cand_news.shape)\n",
        "print(all_train_cand_label.shape)\n",
        "print(all_train_usr_ids.shape)\n",
        "print(all_train_browsed_news.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTLYVkXeqJdv",
        "outputId": "cf53bb62-3d04-472b-feb0-9c260b2b7264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2336, 5)\n",
            "(2336, 5)\n",
            "(2336,)\n",
            "(2336, 50)\n"
          ]
        }
      ],
      "source": [
        "print(all_test_cand_news.shape)\n",
        "print(all_test_cand_label.shape)\n",
        "print(all_test_usr_ids.shape)\n",
        "print(all_test_browsed_news.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AX15GlT_qJdw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class AttentiveMultiView(nn.Module):\n",
        "    def __init__(self, embedding_mat, CAT_LEN, SUBCAT_LEN, DIM_CAT=50, DIM_EMB=300, DIM_CONV_EMB=400, DIM_ATTN=200, NUM_HIER=1, CONTEXT_WIN=3, MAX_SLEN=30):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.DIM_EMB = DIM_EMB\n",
        "        self.DIM_CONV_EMB = DIM_CONV_EMB\n",
        "        self.MAX_SLEN = MAX_SLEN\n",
        "        self.DIM_ATTN = DIM_ATTN \n",
        "\n",
        "        self.cat_embed = nn.Embedding(CAT_LEN, DIM_CAT)\n",
        "        self.subcat_embed = nn.Embedding(SUBCAT_LEN, DIM_CAT)\n",
        "        self.all_c_sc_linear = nn.Linear(DIM_CAT, DIM_CONV_EMB) \n",
        "\n",
        "        self.embed = nn.Embedding.from_pretrained(torch.from_numpy(embedding_mat))\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        # self.conv1d = nn.Conv1d(DIM_EMB, DIM_CONV_EMB, kernel_size=CONTEXT_WIN, padding='same', stride=1)\n",
        "        self.gru = nn.GRU(DIM_EMB, DIM_CONV_EMB, num_layers=2, bidirectional=True)\n",
        "        self.gru_layer = nn.Linear(2*DIM_CONV_EMB, DIM_CONV_EMB)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.attn_layer = nn.Linear(DIM_CONV_EMB, DIM_ATTN)\n",
        "        self.attn_layer2 = nn.Linear(DIM_ATTN, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        self.concat_layer = nn.Linear(DIM_ATTN*NUM_HIER, DIM_ATTN)\n",
        "\n",
        "    def news_encoder(self, batch_news, batch_size, news_words, news_body_words, cat_news_to_id, subcat_news_to_id):\n",
        "        \n",
        "        # Categories\n",
        "        cat_per_row = [cat_news_to_id[batch_news[i]] for i in range(len(batch_news))]\n",
        "        cat_per_row = torch.stack(cat_per_row, axis=0).squeeze(-1)\n",
        "        cat_emb = self.cat_embed(cat_per_row)\n",
        "        r_c = self.all_c_sc_linear(cat_emb).unsqueeze(2)\n",
        "        # print(r_c.shape)\n",
        "\n",
        "        # Subcategories\n",
        "        subcat_per_row = [subcat_news_to_id[batch_news[i]] for i in range(len(batch_news))]\n",
        "        subcat_per_row = torch.stack(subcat_per_row, axis=0).squeeze(-1)\n",
        "        subcat_emb = self.subcat_embed(subcat_per_row)\n",
        "        r_sc = self.all_c_sc_linear(subcat_emb).unsqueeze(2)\n",
        "        # print(r_sc.shape)\n",
        "\n",
        "        # Passing News title\n",
        "        news_per_row = [news_words[batch_news[i]] for i in range(len(batch_news))]\n",
        "        news_per_row = torch.stack(news_per_row, axis=0)\n",
        "        \n",
        "        emb = self.dropout(self.embed(news_per_row))\n",
        "        # TODO: need to check if -1 to put at dim 0 or dim 3\n",
        "        emb = emb.reshape(-1, self.DIM_EMB, self.MAX_SLEN)\n",
        "        context = self.dropout(self.relu(self.gru(emb.permute(0,2,1))[0]))\n",
        "        context = self.gru_layer(context).permute(0,1,2)\n",
        "        context = context.reshape(batch_size, -1, self.MAX_SLEN, self.DIM_CONV_EMB)\n",
        "        attn_t = self.tanh(self.attn_layer(context))\n",
        "        attn_t = self.attn_layer2(attn_t).squeeze()\n",
        "        attn_weights_t = self.softmax(attn_t)\n",
        "        r_t = torch.bmm(context.reshape(-1, self.DIM_CONV_EMB, self.MAX_SLEN), attn_weights_t.reshape(-1, self.MAX_SLEN, 1)).reshape(batch_size, -1, self.DIM_CONV_EMB).unsqueeze(2)\n",
        "        \n",
        "        r_channel = torch.cat([r_c, r_sc, r_t], dim=2)\n",
        "        r_channel = r_channel.reshape(-1, r_channel.shape[2], self.DIM_CONV_EMB)\n",
        "        attn_v = self.tanh(self.attn_layer(r_channel))\n",
        "        attn_v = self.attn_layer2(attn_v).squeeze()\n",
        "        attn_weights_v = self.softmax(attn_v)\n",
        "\n",
        "        # Passing Body title\n",
        "        body_per_row = [news_body_words[batch_news[i]] for i in range(len(batch_news))]\n",
        "        body_per_row = torch.stack(body_per_row, axis=0)\n",
        "\n",
        "        emb = self.dropout(self.embed(body_per_row))\n",
        "        # TODO: need to check if -1 to put at dim 0 or dim 3\n",
        "        emb = emb.reshape(-1, self.DIM_EMB, self.MAX_SLEN)\n",
        "        context = self.dropout(self.relu(self.gru(emb.permute(0,2,1))[0]))\n",
        "        context = self.gru_layer(context).permute(0,1,2)\n",
        "        context = context.reshape(batch_size, -1, self.MAX_SLEN, self.DIM_CONV_EMB)\n",
        "        attn_t = self.tanh(self.attn_layer(context))\n",
        "        attn_t = self.attn_layer2(attn_t).squeeze()\n",
        "        attn_weights_t = self.softmax(attn_t)\n",
        "        r_b = torch.bmm(context.reshape(-1, self.DIM_CONV_EMB, self.MAX_SLEN), attn_weights_t.reshape(-1, self.MAX_SLEN, 1)).reshape(batch_size, -1, self.DIM_CONV_EMB).unsqueeze(2)\n",
        "        \n",
        "        r_channel = torch.cat([r_c, r_sc, r_t, r_b], dim=2)\n",
        "        r_channel = r_channel.reshape(-1, r_channel.shape[2], self.DIM_CONV_EMB)\n",
        "        attn_v = self.tanh(self.attn_layer(r_channel))\n",
        "        attn_v = self.attn_layer2(attn_v).squeeze()\n",
        "        attn_weights_v = self.softmax(attn_v)\n",
        "\n",
        "        output = torch.bmm(r_channel.reshape(-1, self.DIM_CONV_EMB, r_channel.shape[1]), attn_weights_v.reshape(-1, r_channel.shape[1], 1))\n",
        "\n",
        "        return output # 500 x 400 x 1\n",
        "    \n",
        "    def forward(self, batch_cand_news, batch_cand_label, batch_browsed_news, news_words, news_body_words, cat_news_to_id, subcat_news_to_id):\n",
        "        batch_size = batch_cand_news.shape[0]\n",
        "        # Candidate News\n",
        "        candNews_rep = self.news_encoder(batch_cand_news, batch_size, news_words,news_body_words, cat_news_to_id, subcat_news_to_id).reshape(batch_size, -1, self.DIM_CONV_EMB)\n",
        "        # print(candNews_rep.shape)\n",
        "\n",
        "        # Browsed/Clicked News\n",
        "        browNews_rep = self.news_encoder(batch_browsed_news, batch_size, news_words,news_body_words, cat_news_to_id, subcat_news_to_id).reshape(batch_size, -1, self.DIM_CONV_EMB)\n",
        "        attn_n = self.tanh(self.attn_layer(browNews_rep))\n",
        "        attn_n = self.attn_layer2(attn_n).squeeze()\n",
        "        attn_weights_n = self.softmax(attn_n)\n",
        "        user_rep = torch.bmm(browNews_rep.reshape(browNews_rep.shape[0], self.DIM_CONV_EMB, -1), attn_weights_n.unsqueeze(2))\n",
        "        # print(user_rep.shape)\n",
        "        \n",
        "        output = nn.functional.log_softmax(torch.bmm(candNews_rep,user_rep).squeeze(),dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L93h2CDDqJdw"
      },
      "outputs": [],
      "source": [
        "# attentive_mv = AttentiveMultiView(embedding_mat, CAT_LEN = len(cat_to_id), SUBCAT_LEN = len(subcat_to_id), DIM_EMB=300, DIM_CONV_EMB=400, DIM_ATTN=200, NUM_HIER=1, CONTEXT_WIN=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FdJtnLzHqJdw"
      },
      "outputs": [],
      "source": [
        "# x = attentive_mv.forward(torch.LongTensor(all_test_cand_news[:100]), torch.LongTensor(all_test_cand_label[:100]), torch.LongTensor(all_test_browsed_news[:100]), news_words=torch.LongTensor(news_words), news_body_words=torch.LongTensor(news_body_words), cat_news_to_id=torch.LongTensor(cat_news_to_id), subcat_news_to_id=torch.LongTensor(subcat_news_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6isQH5pNqJdx"
      },
      "outputs": [],
      "source": [
        "def train(all_train_cand_news,all_train_cand_label,all_train_browsed_news,all_train_usr_ids,news_words,news_body_words,cat_news_to_id,subcat_news_to_id,model,nEpochs):\n",
        "    #optimizer = optim.Adadelta(lstm.parameters(), lr=0.1)\n",
        "    #TODO: initialize optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    batch_size = 32\n",
        "\n",
        "    for epoch in range(nEpochs):\n",
        "        totalLoss = 0.0\n",
        "        for batch in tqdm.notebook.tqdm(range(0, len(all_train_usr_ids), batch_size), leave=False):\n",
        "            model.zero_grad()\n",
        "            #TODO: Implement gradient update.\n",
        "            batch_cand_news = all_train_cand_news[batch:batch+batch_size,]\n",
        "            batch_cand_label = all_train_cand_label[batch:batch+batch_size]\n",
        "            # batch_id = all_train_id[batch:batch+batch_size]\n",
        "            batch_browsed_news = all_train_browsed_news[batch:batch+batch_size,]\n",
        "\n",
        "\n",
        "            logits = model(torch.LongTensor(batch_cand_news).cuda(), torch.LongTensor(batch_cand_label).cuda(), \n",
        "                              torch.LongTensor(batch_browsed_news).cuda(),torch.LongTensor(news_words).cuda(),torch.LongTensor(news_body_words).cuda(),\n",
        "                              torch.LongTensor(cat_news_to_id).cuda(),torch.LongTensor(subcat_news_to_id).cuda())\n",
        "            loss = nn.functional.cross_entropy(logits.to('cpu'), torch.FloatTensor(batch_cand_label))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            totalLoss += loss.item()\n",
        "            \n",
        "        print(f\"loss on epoch {epoch} = {totalLoss}\")\n",
        "        \n",
        "        # batch_pn = all_test_pn\n",
        "        # batch_label = all_test_label\n",
        "        # batch_id = all_test_id\n",
        "        # batch_user_pos = all_test_user_pos\n",
        "\n",
        "        test_y_scores = []\n",
        "        for batch in tqdm.notebook.tqdm(range(0, len(all_test_usr_ids), batch_size), leave=False):\n",
        "            batch_cand_news = all_test_cand_news[batch:batch+batch_size,]\n",
        "            batch_cand_label = all_test_cand_label[batch:batch+batch_size]\n",
        "            # batch_id = all_train_id[batch:batch+batch_size]\n",
        "            batch_browsed_news = all_test_browsed_news[batch:batch+batch_size,]\n",
        "            logits = model(torch.LongTensor(batch_cand_news).cuda(), torch.LongTensor(batch_cand_label).cuda(), \n",
        "                                  torch.LongTensor(batch_browsed_news).cuda(),torch.LongTensor(news_words).cuda(),torch.LongTensor(news_body_words).cuda(),\n",
        "                                  torch.LongTensor(cat_news_to_id).cuda(),torch.LongTensor(subcat_news_to_id).cuda())\n",
        "            y_score  = logits.detach().cpu().numpy()\n",
        "            test_y_scores.append(y_score)\n",
        "          \n",
        "        test_y_scores = np.array(test_y_scores)\n",
        "        test_y_scores = test_y_scores.reshape(-1, test_y_scores.shape[-1])\n",
        "        mrr_sc = np.mean(np.array([mrr_score(all_test_cand_label[i],test_y_scores[i]) for i in range(len(test_y_scores))]))\n",
        "        rocc_auc_score = np.mean(np.array([roc_auc_score(all_test_cand_label[i],test_y_scores[i]) for i in range(len(test_y_scores))]))\n",
        "        ndcg_5_score = np.mean(np.array([ndcg_score(all_test_cand_label[i],test_y_scores[i],5) for i in range(len(test_y_scores))]))\n",
        "        ndcg_10_score = np.mean(np.array([ndcg_score(all_test_cand_label[i],test_y_scores[i],10) for i in range(len(test_y_scores))]))\n",
        "        print('MRR on test set: '+ str(mrr_sc))\n",
        "        print('ROC-AUC on test set: '+ str(rocc_auc_score))\n",
        "        print('NDCG@5 on test set: '+ str(ndcg_5_score))\n",
        "        print('NDCG@10 on test set: '+ str(ndcg_10_score))\n",
        "        print('----------------------------------------------------------------------------------------------------------')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SottDX4sqJdx"
      },
      "outputs": [],
      "source": [
        "attentive_mv = AttentiveMultiView(embedding_mat, CAT_LEN = len(cat_to_id), SUBCAT_LEN = len(subcat_to_id), DIM_EMB=300, DIM_CONV_EMB=400, DIM_ATTN=200, NUM_HIER=1, CONTEXT_WIN=3).cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HWi8TYUqJdy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b22bacdd5f8b4d1abe35450b45e84cde",
            "f0bc56f742444bd69599f31194aa4641",
            "68e057697bba4ba48d0ad6ca1b70a257",
            "12c436b58af84214acd4c7d55115362a",
            "e842d665787c45bbade33afe0c4f2f44",
            "499e555816d44e0a8eb84389138f834c",
            "4786bb0fc81f475ea4070d6aaac6713c",
            "824576df1b65485bb24af1ff470deabc",
            "a787216c79104ca2b0414b60ed5b72a3",
            "f1bd946203694d4592b7872216208694",
            "4344ec62122643649cf0050907f6c7d1"
          ]
        },
        "outputId": "09bb6fd1-a5eb-4192-f8d2-40eb256a9073"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1698 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b22bacdd5f8b4d1abe35450b45e84cde"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train(all_train_cand_news,all_train_cand_label,all_train_browsed_news,all_train_usr_ids,news_words,news_body_words,cat_news_to_id,subcat_news_to_id,attentive_mv,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9-WPdwuqYH6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRUyDTPlqYLK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b22bacdd5f8b4d1abe35450b45e84cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0bc56f742444bd69599f31194aa4641",
              "IPY_MODEL_68e057697bba4ba48d0ad6ca1b70a257",
              "IPY_MODEL_12c436b58af84214acd4c7d55115362a"
            ],
            "layout": "IPY_MODEL_e842d665787c45bbade33afe0c4f2f44"
          }
        },
        "f0bc56f742444bd69599f31194aa4641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_499e555816d44e0a8eb84389138f834c",
            "placeholder": "​",
            "style": "IPY_MODEL_4786bb0fc81f475ea4070d6aaac6713c",
            "value": "  4%"
          }
        },
        "68e057697bba4ba48d0ad6ca1b70a257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824576df1b65485bb24af1ff470deabc",
            "max": 1698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a787216c79104ca2b0414b60ed5b72a3",
            "value": 64
          }
        },
        "12c436b58af84214acd4c7d55115362a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1bd946203694d4592b7872216208694",
            "placeholder": "​",
            "style": "IPY_MODEL_4344ec62122643649cf0050907f6c7d1",
            "value": " 64/1698 [01:42&lt;44:08,  1.62s/it]"
          }
        },
        "e842d665787c45bbade33afe0c4f2f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499e555816d44e0a8eb84389138f834c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4786bb0fc81f475ea4070d6aaac6713c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "824576df1b65485bb24af1ff470deabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a787216c79104ca2b0414b60ed5b72a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1bd946203694d4592b7872216208694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4344ec62122643649cf0050907f6c7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}