{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Gd_s728FcVH",
    "outputId": "2e6e4cc1-83d2-4c39-c0fe-161198edac8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/expero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy.linalg import cholesky\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm.notebook\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDGcp8O1qJdn",
    "outputId": "945f4146-6168-40a3-af10-46bf45b03b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 22 23:48:33 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.01    Driver Version: 512.78       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   45C    P8    13W /  N/A |    525MiB /  8192MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)\n",
    "\n",
    "print(f'GPU available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmFAw4uiDsyi",
    "outputId": "6c5fb1b0-0b32-47b3-957a-7158c499e808"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3hbAOZx6rFoC"
   },
   "outputs": [],
   "source": [
    "# behaviour_train_file = '/content/drive/My Drive/Courses/NLP/MINDsmall_train/behaviors.tsv'\n",
    "# news_train_file = '/content/drive/My Drive/Courses/NLP/MINDsmall_train/news.tsv'\n",
    "\n",
    "# behaviour_dev_file = '/content/drive/My Drive/Courses/NLP/MINDsmall_dev/behaviors.tsv'\n",
    "# news_dev_file = '/content/drive/My Drive/Courses/NLP/MINDsmall_dev/news.tsv'\n",
    "\n",
    "behaviour_train_file = 'MINDsmall_train/behaviors.tsv'\n",
    "news_train_file = 'MINDsmall_train/news.tsv'\n",
    "\n",
    "behaviour_dev_file = 'MINDsmall_dev/behaviors.tsv'\n",
    "news_dev_file = 'MINDsmall_dev/news.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JYjzMlDvFa3g"
   },
   "outputs": [],
   "source": [
    "def newsample(nnn,ratio):\n",
    "    if ratio >len(nnn):\n",
    "        return random.sample(nnn*(ratio//len(nnn)+1),ratio)\n",
    "    else:\n",
    "        return random.sample(nnn,ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgWlqyXjaABh",
    "outputId": "df37ef2f-a6cf-4a02-bf4f-73f0c60ddaae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20772 37536\n"
     ]
    }
   ],
   "source": [
    "################# Reading news data \n",
    "# max_sentence_len = 0\n",
    "sent_len_for_model = 30\n",
    "with open(news_train_file) as news_f:\n",
    "  news_k = news_f.readlines()\n",
    "\n",
    "news_dict = {}\n",
    "content ={}\n",
    "word_dict_raw={'PADDING':[0,999999]}\n",
    "\n",
    "i=0\n",
    "for doc in news_k:\n",
    "  d = doc.strip().split('\\t')\n",
    "  newsid = d[0]\n",
    "  ## Format is id,category,sub-category,Title,Abstract,link,Wikidata/metadata\n",
    "  if newsid not in news_dict:\n",
    "    news_dict[newsid] = len(news_dict)\n",
    "    tokenized_news = word_tokenize(d[3].lower())\n",
    "    # max_sentence_len = max(max_sentence_len,len(tokenized_news))\n",
    "    content[news_dict[newsid]] = [d[1].lower(),d[2].lower(),tokenized_news]\n",
    "    for word in tokenized_news:\n",
    "        if word in word_dict_raw:\n",
    "            word_dict_raw[word][1]+=1\n",
    "        else:\n",
    "            word_dict_raw[word]=[len(word_dict_raw),1]\n",
    "\n",
    "word_dict={}\n",
    "for i in word_dict_raw:\n",
    "    if word_dict_raw[i][1]>=2:\n",
    "        word_dict[i]=[len(word_dict),word_dict_raw[i][1]]\n",
    "print(len(word_dict),len(word_dict_raw))\n",
    "##### words for each news\n",
    "news_words=[]\n",
    "news_index={}\n",
    "for newsid in content:\n",
    "    word_id=[]\n",
    "    news_dict[newsid]=len(news_index)\n",
    "    for word in content[newsid][2]:\n",
    "        if word in word_dict:\n",
    "            word_id.append(word_dict[word][0])\n",
    "    word_id=word_id[:30]\n",
    "    news_words.append(word_id+[0]*(30-len(word_id)))\n",
    "news_words=np.array(news_words,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sQHJw1HOVdpV"
   },
   "outputs": [],
   "source": [
    "cat_to_id = {}\n",
    "cat_news_to_id = []\n",
    "subcat_to_id = {}\n",
    "subcat_news_to_id = []\n",
    "\n",
    "for newsid in content: \n",
    "    cat = content[newsid][0]\n",
    "    if cat not in cat_to_id:\n",
    "        cat_to_id[cat] = len(cat_to_id)\n",
    "    \n",
    "    subcat = content[newsid][1]\n",
    "    if subcat not in subcat_to_id:\n",
    "        subcat_to_id[subcat] = len(subcat_to_id)\n",
    "\n",
    "for newsid in content: \n",
    "    cat_news_to_id.append([cat_to_id[content[newsid][0]]])\n",
    "    subcat_news_to_id.append([subcat_to_id[content[newsid][1]]])\n",
    "\n",
    "cat_news_to_id=np.array(cat_news_to_id ,dtype='int32')\n",
    "subcat_news_to_id=np.array(subcat_news_to_id ,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YgvY5XQTDiPE"
   },
   "outputs": [],
   "source": [
    "def get_embedding(word_dict):\n",
    "    embedding_dict={}\n",
    "    cnt=0\n",
    "    # with open('/data/wuch/glove.840B.300d.txt','rb')as f:\n",
    "    # with open('/content/drive/My Drive/Courses/NLP/glove.840B.300d.txt','rb') as f:\n",
    "    with open('glove.840B.300d.txt','rb') as f:\n",
    "        linenb=0\n",
    "        while True:\n",
    "            line=f.readline()\n",
    "            if len(line)==0:\n",
    "                break\n",
    "            line = line.split()\n",
    "            word=line[0].decode()\n",
    "            linenb+=1\n",
    "            if len(word) != 0:\n",
    "                vec=[float(x) for x in line[1:]]\n",
    "                if word in word_dict:\n",
    "                    embedding_dict[word]=vec\n",
    "                    if cnt%1000==0:\n",
    "                        print(cnt,linenb,word)\n",
    "                    cnt+=1\n",
    "\n",
    "    embedding_matrix=[0]*len(word_dict)\n",
    "    cand=[]\n",
    "    for i in embedding_dict:\n",
    "        embedding_matrix[word_dict[i][0]]=np.array(embedding_dict[i],dtype='float32')\n",
    "        cand.append(embedding_matrix[word_dict[i][0]])\n",
    "    cand=np.array(cand,dtype='float32')\n",
    "    mu=np.mean(cand, axis=0)\n",
    "    Sigma=np.cov(cand.T)\n",
    "    norm=np.random.multivariate_normal(mu, Sigma, 1)\n",
    "    for i in range(len(embedding_matrix)):\n",
    "        if type(embedding_matrix[i])==int:\n",
    "            embedding_matrix[i]=np.reshape(norm, 300)\n",
    "    embedding_matrix[0]=np.zeros(300,dtype='float32')\n",
    "    embedding_matrix=np.array(embedding_matrix,dtype='float32')\n",
    "    # print(embedding_matrix.shape)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUQT_mz0qX4T",
    "outputId": "aab5d1f1-8d01-4fc2-caa3-6043794e129d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ,\n",
      "1000 1326 situation\n",
      "2000 2903 v.\n",
      "3000 4611 solve\n",
      "4000 6541 suicide\n",
      "5000 8816 resolved\n",
      "6000 11463 sticky\n",
      "7000 14534 protesters\n",
      "8000 18348 noises\n",
      "9000 22934 qualifies\n",
      "10000 28630 ordeal\n",
      "11000 36112 amazes\n",
      "12000 46352 nugget\n",
      "13000 60191 charleston\n",
      "14000 81502 shaw\n",
      "15000 113411 williamsburg\n",
      "16000 169878 re-opens\n",
      "17000 284973 parr\n",
      "18000 592101 hoda\n"
     ]
    }
   ],
   "source": [
    "embedding_mat=get_embedding(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzF63Xn7Xh-S"
   },
   "source": [
    "Sampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "K5zc-PfNYCHf"
   },
   "outputs": [],
   "source": [
    "################# Reading click behavior data \n",
    "min_neg_samples_required = 10\n",
    "npratio = 4\n",
    "#########################\n",
    "with open(behaviour_train_file) as f2:\n",
    "  userdata_new = f2.readlines()\n",
    "\n",
    "userid_dict_total = {}\n",
    "cnt_gr = 0\n",
    "cnt = 0 \n",
    "############################################\n",
    "all_train_id=[]\n",
    "all_train_pn=[]    \n",
    "all_label=[]\n",
    "all_user_pos=[]\n",
    "\n",
    "############################################\n",
    "\n",
    "for user in userdata_new:\n",
    "  cnt +=1\n",
    "  line = user.strip().split('\\t')\n",
    "  userid = line[1]\n",
    "  impre_id = line[0]\n",
    "  if userid not in userid_dict_total:\n",
    "    userid_dict_total[userid] = len(userid_dict_total)\n",
    "  click_history = line[3].strip().split()\n",
    "  new_line = line[4].strip().split()\n",
    "  trainpos=[x.split('-')[0]  for x in new_line if x[-1]=='1']\n",
    "  trainneg=[x.split('-')[0] for x in new_line if x[-1]=='0']\n",
    "  \n",
    "  if len(trainneg) > 0:\n",
    "      for pos_sample in trainpos:\n",
    "          pos_neg_sample = newsample(trainneg,npratio)\n",
    "          pos_neg_sample.append(pos_sample)\n",
    "          temp_label=[0 for i in range(npratio)]+[1]\n",
    "          temp_id=list(range(npratio+1))\n",
    "          random.shuffle(temp_id)\n",
    "\n",
    "          shuffle_sample=[]\n",
    "          shuffle_label=[]\n",
    "          for id in temp_id:\n",
    "              shuffle_sample.append(news_dict[pos_neg_sample[id]])\n",
    "              shuffle_label.append(temp_label[id])\n",
    "          posset=list(set(click_history)-set([pos_sample]))\n",
    "          allpos=[news_dict[p] for p in random.sample(posset,min(50,len(posset)))[:50]]\n",
    "          allpos+=[0]*(50-len(allpos))\n",
    "          all_train_pn.append(shuffle_sample)\n",
    "          all_label.append(shuffle_label)\n",
    "          all_train_id.append(userid_dict_total[userid])\n",
    "          all_user_pos.append(allpos)\n",
    "############################################\n",
    "all_train_pn_total=np.array(all_train_pn,dtype='int32')\n",
    "all_label_total=np.array(all_label,dtype='int32')\n",
    "all_train_id_total=np.array(all_train_id,dtype='int32')\n",
    "all_user_pos_total=np.array(all_user_pos,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N9vqWWHwqX6g"
   },
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WP6ZbgjtqX_c"
   },
   "outputs": [],
   "source": [
    "def generate_batch_data_test(all_test_pn,all_label,all_test_id,batch_size):\n",
    "    inputid = np.arange(len(all_label))\n",
    "    y=all_label\n",
    "    batches = [inputid[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            candidate = news_words[all_test_pn[i]]\n",
    "            browsed_news=news_words[all_test_user_pos[i]]\n",
    "            browsed_news_split=[browsed_news[:,k,:] for k in range(browsed_news.shape[1])]\n",
    "            userid=np.expand_dims(all_test_id[i],axis=1)\n",
    "            label=all_label[i]\n",
    "\n",
    "            yield ([candidate]+ browsed_news_split+[userid], label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHZtMR6cbCYa",
    "outputId": "bf5dc70e-80af-4e9e-9144-186884b80af9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236344, 5)\n",
      "(236344, 5)\n",
      "(236344,)\n",
      "(236344, 50)\n"
     ]
    }
   ],
   "source": [
    "print(all_train_pn_total.shape)\n",
    "print(all_label_total.shape)\n",
    "print(all_train_id_total.shape)\n",
    "print(all_user_pos_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yGMZyJkyJfKI"
   },
   "outputs": [],
   "source": [
    "unique_users,user_counts = np.unique(all_train_id_total,return_counts=True)\n",
    "selected_user_ids = unique_users[user_counts>15]\n",
    "########################\n",
    "final_id_mask = np.isin(all_train_id_total,selected_user_ids)\n",
    "\n",
    "final_pn_total= all_train_pn_total[final_id_mask,]\n",
    "final_label_total = all_label_total[final_id_mask,]\n",
    "final_id_total = all_train_id_total[final_id_mask]\n",
    "final_user_pos_total = all_user_pos_total[final_id_mask,]\n",
    "###################\n",
    "unique_id,first_occurance = np.unique(np.flip(final_id_total),return_index=True)\n",
    "final_index = len(final_id_total)-1-first_occurance\n",
    "######################\n",
    "all_index = np.array(range(0,len(final_id_total)))\n",
    "\n",
    "test_index = np.isin(all_index,final_index)\n",
    "\n",
    "train_index = ~test_index\n",
    "##########################\n",
    "all_test_cand_news = final_pn_total[test_index,]\n",
    "all_test_cand_label = final_label_total[test_index,]\n",
    "all_test_usr_ids = final_id_total[test_index]\n",
    "all_test_browsed_news = final_user_pos_total[test_index,]\n",
    "# all_test_index = np.array(range(0,len(all_test_usr_ids)))\n",
    "\n",
    "all_train_cand_news = final_pn_total[train_index,]\n",
    "all_train_cand_label = final_label_total[train_index,]\n",
    "all_train_usr_ids = final_id_total[train_index]\n",
    "all_train_browsed_news = final_user_pos_total[train_index,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivVwZ2NMY5qm",
    "outputId": "ef1cfa50-4a47-49a7-f053-3d401b569452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54335, 5)\n",
      "(54335, 5)\n",
      "(54335,)\n",
      "(54335, 50)\n"
     ]
    }
   ],
   "source": [
    "print(all_train_cand_news.shape)\n",
    "print(all_train_cand_label.shape)\n",
    "print(all_train_usr_ids.shape)\n",
    "print(all_train_browsed_news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTLYVkXeqJdv",
    "outputId": "134ca8d0-a9f2-4deb-83f5-c359b69a19ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2336, 5)\n",
      "(2336, 5)\n",
      "(2336,)\n",
      "(2336, 50)\n"
     ]
    }
   ],
   "source": [
    "print(all_test_cand_news.shape)\n",
    "print(all_test_cand_label.shape)\n",
    "print(all_test_usr_ids.shape)\n",
    "print(all_test_browsed_news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AX15GlT_qJdw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class AttentiveMultiView(nn.Module):\n",
    "    def __init__(self, embedding_mat, CAT_LEN, SUBCAT_LEN, DIM_CAT=50, DIM_EMB=300, DIM_CONV_EMB=400, DIM_ATTN=200, NUM_HIER=1, CONTEXT_WIN=3, MAX_SLEN=30):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.DIM_EMB = DIM_EMB\n",
    "        self.DIM_CONV_EMB = DIM_CONV_EMB\n",
    "        self.MAX_SLEN = MAX_SLEN\n",
    "        self.DIM_ATTN = DIM_ATTN \n",
    "\n",
    "        self.cat_embed = nn.Embedding(CAT_LEN, DIM_CAT)\n",
    "        self.subcat_embed = nn.Embedding(SUBCAT_LEN, DIM_CAT)\n",
    "        self.all_c_sc_linear = nn.Linear(DIM_CAT, DIM_CONV_EMB) \n",
    "\n",
    "        self.embed = nn.Embedding.from_pretrained(torch.from_numpy(embedding_mat))\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.conv1d = nn.Conv1d(DIM_EMB, DIM_CONV_EMB, kernel_size=CONTEXT_WIN, padding='same', stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.attn_layer = nn.Linear(DIM_CONV_EMB, DIM_ATTN)\n",
    "        self.attn_layer2 = nn.Linear(DIM_ATTN, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.concat_layer = nn.Linear(DIM_ATTN*NUM_HIER, DIM_ATTN)\n",
    "\n",
    "    def news_encoder(self, batch_news, batch_size, news_words, cat_news_to_id, subcat_news_to_id):\n",
    "        \n",
    "        # Categories\n",
    "        cat_per_row = [cat_news_to_id[batch_news[i]] for i in range(len(batch_news))]\n",
    "        cat_per_row = torch.stack(cat_per_row, axis=0).squeeze(-1)\n",
    "        cat_emb = self.cat_embed(cat_per_row)\n",
    "        r_c = self.all_c_sc_linear(cat_emb).unsqueeze(2)\n",
    "        # print(r_c.shape)\n",
    "\n",
    "        # Subcategories\n",
    "        subcat_per_row = [subcat_news_to_id[batch_news[i]] for i in range(len(batch_news))]\n",
    "        subcat_per_row = torch.stack(subcat_per_row, axis=0).squeeze(-1)\n",
    "        subcat_emb = self.subcat_embed(subcat_per_row)\n",
    "        r_sc = self.all_c_sc_linear(subcat_emb).unsqueeze(2)\n",
    "        # print(r_sc.shape)\n",
    "\n",
    "        # Passing News title\n",
    "        news_per_row = [news_words[batch_news[i]] for i in range(len(batch_news))]\n",
    "        news_per_row = torch.stack(news_per_row, axis=0)\n",
    "        \n",
    "        emb = self.dropout(self.embed(news_per_row))\n",
    "        # TODO: need to check if -1 to put at dim 0 or dim 3\n",
    "        emb = emb.reshape(-1, self.DIM_EMB, self.MAX_SLEN)\n",
    "        context = self.dropout(self.relu(self.conv1d(emb)))\n",
    "        context = context.reshape(batch_size, -1, self.MAX_SLEN, self.DIM_CONV_EMB)\n",
    "        attn_t = self.tanh(self.attn_layer(context))\n",
    "        attn_t = self.attn_layer2(attn_t).squeeze()\n",
    "        attn_weights_t = self.softmax(attn_t)\n",
    "        r_t = torch.bmm(context.reshape(-1, self.DIM_CONV_EMB, self.MAX_SLEN), attn_weights_t.reshape(-1, self.MAX_SLEN, 1)).reshape(batch_size, -1, self.DIM_CONV_EMB).unsqueeze(2)\n",
    "        \n",
    "        r_channel = torch.cat([r_c, r_sc, r_t], dim=2)\n",
    "        r_channel = r_channel.reshape(-1, r_channel.shape[2], self.DIM_CONV_EMB)\n",
    "        attn_v = self.tanh(self.attn_layer(r_channel))\n",
    "        attn_v = self.attn_layer2(attn_v).squeeze()\n",
    "        attn_weights_v = self.softmax(attn_v)\n",
    "        output = torch.bmm(r_channel.reshape(-1, self.DIM_CONV_EMB, r_channel.shape[1]), attn_weights_v.reshape(-1, r_channel.shape[1], 1))\n",
    "\n",
    "        return output # 500 x 400 x 1\n",
    "    \n",
    "    def forward(self, batch_cand_news, batch_cand_label, batch_browsed_news, news_words, cat_news_to_id, subcat_news_to_id):\n",
    "        batch_size = batch_cand_news.shape[0]\n",
    "\n",
    "        # Candidate News\n",
    "        candNews_rep = self.news_encoder(batch_cand_news, batch_size, news_words, cat_news_to_id, subcat_news_to_id).reshape(batch_size, -1, self.DIM_CONV_EMB)\n",
    "        # print(candNews_rep.shape)\n",
    "\n",
    "        # Browsed/Clicked News\n",
    "        browNews_rep = self.news_encoder(batch_browsed_news, batch_size, news_words, cat_news_to_id, subcat_news_to_id).reshape(batch_size, -1, self.DIM_CONV_EMB)\n",
    "        attn_n = self.tanh(self.attn_layer(browNews_rep))\n",
    "        attn_n = self.attn_layer2(attn_n).squeeze()\n",
    "        attn_weights_n = self.softmax(attn_n)\n",
    "        user_rep = torch.bmm(browNews_rep.reshape(browNews_rep.shape[0], self.DIM_CONV_EMB, -1), attn_weights_n.unsqueeze(2))\n",
    "        # print(user_rep.shape)\n",
    "        \n",
    "        output = nn.functional.log_softmax(torch.bmm(candNews_rep,user_rep).squeeze(),dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "L93h2CDDqJdw"
   },
   "outputs": [],
   "source": [
    "# attentive_mv = AttentiveMultiView(embedding_mat, CAT_LEN = len(cat_to_id), SUBCAT_LEN = len(subcat_to_id), DIM_EMB=300, DIM_CONV_EMB=400, DIM_ATTN=200, NUM_HIER=1, CONTEXT_WIN=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FdJtnLzHqJdw"
   },
   "outputs": [],
   "source": [
    "# x = attentive_mv.forward(torch.LongTensor(all_test_cand_news[:100]), torch.LongTensor(all_test_cand_label[:100]), torch.LongTensor(all_test_browsed_news[:100]), news_words=torch.LongTensor(news_words), cat_news_to_id=torch.LongTensor(cat_news_to_id), subcat_news_to_id=torch.LongTensor(subcat_news_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6isQH5pNqJdx"
   },
   "outputs": [],
   "source": [
    "def train(all_train_cand_news,all_train_cand_label,all_train_browsed_news,all_train_usr_ids,news_words,cat_news_to_id,subcat_news_to_id,model,nEpochs):\n",
    "    #optimizer = optim.Adadelta(lstm.parameters(), lr=0.1)\n",
    "    #TODO: initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    batch_size = 16\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        totalLoss = 0.0\n",
    "        for batch in tqdm.notebook.tqdm(range(0, len(all_train_usr_ids), batch_size), leave=False):\n",
    "            model.zero_grad()\n",
    "            #TODO: Implement gradient update.\n",
    "            batch_cand_news = all_train_cand_news[batch:batch+batch_size,]\n",
    "            batch_cand_label = all_train_cand_label[batch:batch+batch_size]\n",
    "            # batch_id = all_train_id[batch:batch+batch_size]\n",
    "            batch_browsed_news = all_train_browsed_news[batch:batch+batch_size,]\n",
    "\n",
    "\n",
    "            logits = model(torch.LongTensor(batch_cand_news).cuda(), torch.LongTensor(batch_cand_label).cuda(), \n",
    "                              torch.LongTensor(batch_browsed_news).cuda(),torch.LongTensor(news_words).cuda(),\n",
    "                              torch.LongTensor(cat_news_to_id).cuda(),torch.LongTensor(subcat_news_to_id).cuda())\n",
    "            loss = nn.functional.cross_entropy(logits.to('cpu'), torch.FloatTensor(batch_cand_label))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            totalLoss += loss.item()\n",
    "            \n",
    "        print(f\"loss on epoch {epoch} = {totalLoss}\")\n",
    "        \n",
    "        # batch_pn = all_test_pn\n",
    "        # batch_label = all_test_label\n",
    "        # batch_id = all_test_id\n",
    "        # batch_user_pos = all_test_user_pos\n",
    "\n",
    "        test_y_scores = []\n",
    "        for batch in tqdm.notebook.tqdm(range(0, len(all_test_usr_ids), batch_size), leave=False):\n",
    "            batch_cand_news = all_test_cand_news[batch:batch+batch_size,]\n",
    "            batch_cand_label = all_test_cand_label[batch:batch+batch_size]\n",
    "            # batch_id = all_train_id[batch:batch+batch_size]\n",
    "            batch_browsed_news = all_test_browsed_news[batch:batch+batch_size,]\n",
    "            logits = model(torch.LongTensor(batch_cand_news).cuda(), torch.LongTensor(batch_cand_label).cuda(), \n",
    "                                  torch.LongTensor(batch_browsed_news).cuda(),torch.LongTensor(news_words).cuda())\n",
    "            y_score  = logits.detach().cpu().numpy()\n",
    "            test_y_scores.append(y_score)\n",
    "          \n",
    "        test_y_scores = np.array(test_y_scores)\n",
    "        test_y_scores = test_y_scores.reshape(-1, test_y_scores.shape[-1])\n",
    "        mrr_sc = np.mean(np.array([mrr_score(all_test_cand_label[i],test_y_scores[i]) for i in range(len(test_y_scores))]))\n",
    "        rocc_auc_score = np.mean(np.array([roc_auc_score(all_test_cand_label[i],test_y_scores[i]) for i in range(len(test_y_scores))]))\n",
    "        ndcg_5_score = np.mean(np.array([ndcg_score(all_test_cand_label[i],test_y_scores[i],5) for i in range(len(test_y_scores))]))\n",
    "        ndcg_10_score = np.mean(np.array([ndcg_score(all_test_cand_label[i],test_y_scores[i],10) for i in range(len(test_y_scores))]))\n",
    "        print('MRR on test set: '+ str(mrr_sc))\n",
    "        print('ROC-AUC on test set: '+ str(rocc_auc_score))\n",
    "        print('NDCG@5 on test set: '+ str(ndcg_5_score))\n",
    "        print('NDCG@10 on test set: '+ str(ndcg_10_score))\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "SottDX4sqJdx",
    "outputId": "80dfa375-e2a3-4553-a289-e14e635c53f6"
   },
   "outputs": [],
   "source": [
    "attentive_mv = AttentiveMultiView(embedding_mat, CAT_LEN = len(cat_to_id), SUBCAT_LEN = len(subcat_to_id), DIM_EMB=300, DIM_CONV_EMB=400, DIM_ATTN=200, NUM_HIER=1, CONTEXT_WIN=3).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HWi8TYUqJdy"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa3664f50dc4dac8381d592f1323962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(all_train_cand_news,all_train_cand_label,all_train_browsed_news,all_train_usr_ids,news_words,cat_news_to_id,subcat_news_to_id,attentive_mv,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9-WPdwuqYH6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRUyDTPlqYLK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
